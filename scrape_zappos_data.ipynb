{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web scraping test\n",
    "! pip install BeautifulSoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import urllib\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Put the logic below to gather and parse data into a loop, because we want to grab data from all pages.\n",
    "# This search and website is for women's boots. \n",
    "# As of 7/2/2019 there are 46 pages, and the last page should be 'https://www.zappos.com/women-boots/CK_XARCz1wHAAQHiAgMBAhg.zso?p=45'\n",
    "# Here is a link to example code that should help with this, but it didn't work for me\n",
    "# https://stackoverflow.com/questions/16778435/python-check-if-website-exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open page for Women's boots on Zappos\n",
    "source_url = 'https://www.zappos.com/women-boots/CK_XARCz1wHAAQHiAgMBAhg.zso'\n",
    "page = urllib.request.urlopen(source_url)\n",
    "soup = BeautifulSoup(page, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse data based on the structure of the page\n",
    "# We are going to create a dictionary that we will then write to a json file\n",
    "# Each dictionary key will be the name of the image\n",
    "\n",
    "# Note the following constructs: \n",
    "\n",
    "data_dict = {}\n",
    "\n",
    "\n",
    "for link in soup.find_all('a'):\n",
    "    aria_label = link.get('aria-label')\n",
    "    if aria_label and link.img:\n",
    "        # Sort to make sure that what we get back has a price, ensuring it is a boot we want to include\n",
    "        if aria_label.find('$') != -1:\n",
    "            key = link.img['src'].split('/')[-1] # Use the image name as the key\n",
    "            \n",
    "            # NOTE: We need to use regular expressions here. Splitting on . fails. \n",
    "            attributes = aria_label.split('.')\n",
    "            print(attributes)\n",
    "            data_dict[key] = {'shoe_name': attributes[0],\n",
    "                              'brand': attributes[1].split('By')[1],\n",
    "                              'price': attributes[2] + '.' + attributes[3],\n",
    "                              'style': attributes[4].split('Style:')[1],\n",
    "                              'image_source': link.img['src']}\n",
    "            # We may also want to add the rating but I am leaving it out for now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
