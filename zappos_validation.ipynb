{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "zappos_validation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wXziV9m-_wY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code to validate image similarity models. \n",
        "# This was originally used to compare resnet and squeezenet, and test half precision weights \n",
        "\n",
        "# Assumes you trained two models using code similar to zappos_boot_finder.ipynb\n",
        "model = tc.image_similarity.create(boot_data, model=\"resnet-50\")\n",
        "\n",
        "\n",
        "# Build image similarity model using SqueezeNet, as it is smaller than Resnet\n",
        "model2 = tc.image_similarity.create(boot_data, model=\"squeezenet_v1.1\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gjrqIv6A--1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Query example data. In the first, we look at the most similar images for rows 0-3 of the SFrame. In the second, 3000-3005.\n",
        "# We can do this as many times\n",
        "\n",
        "# In each of these examples, the top result should be the boot itself, since all of the images in boot_data were included in the training. \n",
        "model.query(boot_data[0:3], k=3)\n",
        "model.query(boot_data[3000:3005], k=3)\n",
        "\n",
        "# Now query the squeezenet model to compare results\n",
        "model2.query(boot_data[0:3], k=3)\n",
        "model2.query(boot_data[3000:3005], k=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWTNmUqUBxD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visually inspect sample images based on the metadata that was returned with the json\n",
        "boot_data[3000]\n",
        "boot_data[1126]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5lb099YB1Vi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Can reduce weights in resnet before converting to CoreML, but to my knowledge, there is currently no way to test this in a notebook. \n",
        "# ie we cannot convert to half precision, then back to Turi, to test the results in a notebook. \n",
        "model_spec = coremltools.utils.load_spec(coreml_model_name)\n",
        "model_fp16_spec = coremltools.utils.convert_neural_network_spec_weights_to_fp16(model_spec)\n",
        "coremltools.utils.save_spec(model_fp16_spec, coreml_model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}